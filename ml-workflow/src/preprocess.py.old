# ml-workflow/src/preprocess.py
import pandas as pd
import zipfile
import time
import os
import sys
import requests
import numpy as np

DATA_DUPLICATION_FACTOR = 6

OUTPUT_PATH = '/data/preprocessed_retail_data.csv'
os.makedirs('/data', exist_ok=True)

print("--- Phase 1: Datenvorverarbeitung (Natural Load) gestartet ---", flush=True)
script_start_time = time.time()

zip_file = "online+retail+ii.zip"
url = "https://archive.ics.uci.edu/static/public/502/online+retail+ii.zip"

# --- 1. Download ---
if os.path.exists(zip_file):
    print(f"Datensatz '{zip_file}' lokal vorhanden.", flush=True)
else:
    print(f"Lade Datensatz von {url}...", flush=True)
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        r = requests.get(url, timeout=120, headers=headers)
        with open(zip_file, "wb") as f:
            f.write(r.content)
    except Exception as e:
        print(f"Download Fehler: {e}", file=sys.stderr)
        sys.exit(1)

# --- 2. Entpacken & Lesen ---
print("Entpacke und lese Daten...", flush=True)
with zipfile.ZipFile(zip_file, 'r') as z:
    with z.open(z.namelist()[0]) as excel_file:
        df_orig = pd.read_excel(excel_file)

print(f"Original Daten geladen: {df_orig.shape}", flush=True)

# --- 3. Last-Skalierung (Daten vervielfachen) ---
print(f"Skalierung: Vervielfache Datenmenge um Faktor {DATA_DUPLICATION_FACTOR}...", flush=True)
df = pd.concat([df_orig] * DATA_DUPLICATION_FACTOR, ignore_index=True)
print(f"Neue Datensatzgröße: {df.shape} (ca. {df.memory_usage(deep=True).sum() / 1024**2:.0f} MB RAM)", flush=True)

# --- 4. Bereinigung ---
print("Starte Bereinigung...", flush=True)
df.dropna(subset=['Customer ID', 'Description'], inplace=True)
df = df[df['Quantity'] > 0]
df['Customer ID'] = df['Customer ID'].astype(int)
df['TotalPrice'] = df['Quantity'] * df['Price']

# --- 5. Complex Feature Engineering (RFM Analyse Simulation) ---
#print("Führe komplexe statistische Aggregationen durch (RFM-Style)...", flush=True)

# A. Umfangreiche GroupBy Operationen (CPU intensiv)
# Wir berechnen für jeden Kunden diverse Metriken
#customer_stats = df.groupby('Customer ID').agg({
#    'TotalPrice': ['sum', 'mean', 'std', 'min', 'max'],
#    'Quantity': ['sum', 'mean'],
#    'Invoice': 'nunique',
#    'Description': 'count'
#})

# B. Text-Verarbeitung (Teuer!)
# Wir suchen nach Keywords in der Beschreibung und erstellen Flags
#print("Führe Text-Analyse auf 'Description' durch...", flush=True)
#df['Is_Bag'] = df['Description'].str.contains('BAG', na=False)
#df['Is_Box'] = df['Description'].str.contains('BOX', na=False)
#df['Is_Set'] = df['Description'].str.contains('SET', na=False)
#df['Desc_Len'] = df['Description'].str.len()

# C. Zeitreihen-Operationen (Teuer!)
#print("Führe Zeitreihen-Berechnungen durch...", flush=True)
#df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])
#df['Year'] = df['InvoiceDate'].dt.year
#df['Month'] = df['InvoiceDate'].dt.month
#df['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek
#df['Hour'] = df['InvoiceDate'].dt.hour

# --- 6. Speichern ---
print(f"Speichere Daten nach {OUTPUT_PATH}...", flush=True)
df.to_csv(OUTPUT_PATH, index=False)

total_duration = time.time() - script_start_time
print(f"Gesamtdauer: {total_duration:.2f} Sekunden.", flush=True)
